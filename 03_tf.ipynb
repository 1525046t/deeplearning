{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "\n",
    "class DNN(Model):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = Dense(hidden_dim, activation='relu')\n",
    "        self.d1 = Dropout(0.5)\n",
    "        self.l2 = Dense(hidden_dim, activation='relu')\n",
    "        self.d2 = Dropout(0.5)\n",
    "        self.l3 = Dense(hidden_dim, activation='relu')\n",
    "        self.d3 = Dropout(0.5)\n",
    "        self.l4 = Dense(output_dim, activation='softmax')\n",
    "\n",
    "        self.ls = [self.l1, self.d1,\n",
    "                   self.l2, self.d2,\n",
    "                   self.l3, self.d3,\n",
    "                   self.l4]\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.ls:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(123)\n",
    "    tf.random.set_seed(123)\n",
    "\n",
    "    '''\n",
    "    1. データの準備\n",
    "    '''\n",
    "    mnist = datasets.mnist\n",
    "    (x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
    "\n",
    "    x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "    x_test = (x_test.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "    x_train, x_val, t_train, t_val = \\\n",
    "        train_test_split(x_train, t_train, test_size=0.2)\n",
    "\n",
    "    '''\n",
    "    2. モデルの構築\n",
    "    '''\n",
    "    model = DNN(200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=losses.SparseCategoricalCrossentropy()\n",
    "optimizer=optimizers.SGD(learning_rate=0.01)\n",
    "train_loss=metrics.Mean()\n",
    "train_acc=metrics.SparseCategoricalAccuracy()\n",
    "val_loss=metrics.Mean()\n",
    "val_acc=metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def compute_loss(t,y):\n",
    "    return criterion(t,y)\n",
    "\n",
    "def train_step(x,t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds=model(x)\n",
    "        loss=compute_loss(t,preds)\n",
    "    grads=tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_acc=(t,preds)\n",
    "    return loss\n",
    "\n",
    "def val_step(x,t):\n",
    "    preds=model(x)\n",
    "    loss=compute_loss(t,preds)\n",
    "    val_loss(loss)\n",
    "    val_acc(t,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.22, acc: 0.000, val_loss: 0.548, val_acc: 0.857\n",
      "epoch: 2, loss: 0.829, acc: 0.000, val_loss: 0.465, val_acc: 0.873\n",
      "epoch: 3, loss: 0.669, acc: 0.000, val_loss: 0.42, val_acc: 0.883\n",
      "epoch: 4, loss: 0.579, acc: 0.000, val_loss: 0.39, val_acc: 0.890\n",
      "epoch: 5, loss: 0.52, acc: 0.000, val_loss: 0.368, val_acc: 0.896\n",
      "epoch: 6, loss: 0.477, acc: 0.000, val_loss: 0.35, val_acc: 0.900\n",
      "epoch: 7, loss: 0.443, acc: 0.000, val_loss: 0.335, val_acc: 0.904\n",
      "epoch: 8, loss: 0.417, acc: 0.000, val_loss: 0.323, val_acc: 0.907\n",
      "epoch: 9, loss: 0.394, acc: 0.000, val_loss: 0.312, val_acc: 0.910\n",
      "epoch: 10, loss: 0.375, acc: 0.000, val_loss: 0.302, val_acc: 0.913\n",
      "epoch: 11, loss: 0.359, acc: 0.000, val_loss: 0.293, val_acc: 0.915\n",
      "epoch: 12, loss: 0.344, acc: 0.000, val_loss: 0.285, val_acc: 0.918\n",
      "epoch: 13, loss: 0.331, acc: 0.000, val_loss: 0.277, val_acc: 0.920\n",
      "epoch: 14, loss: 0.32, acc: 0.000, val_loss: 0.27, val_acc: 0.921\n",
      "epoch: 15, loss: 0.309, acc: 0.000, val_loss: 0.264, val_acc: 0.923\n",
      "epoch: 16, loss: 0.299, acc: 0.000, val_loss: 0.258, val_acc: 0.925\n",
      "epoch: 17, loss: 0.29, acc: 0.000, val_loss: 0.252, val_acc: 0.926\n",
      "epoch: 18, loss: 0.282, acc: 0.000, val_loss: 0.247, val_acc: 0.928\n",
      "epoch: 19, loss: 0.274, acc: 0.000, val_loss: 0.242, val_acc: 0.929\n",
      "epoch: 20, loss: 0.267, acc: 0.000, val_loss: 0.237, val_acc: 0.930\n",
      "epoch: 21, loss: 0.26, acc: 0.000, val_loss: 0.232, val_acc: 0.932\n",
      "epoch: 22, loss: 0.254, acc: 0.000, val_loss: 0.228, val_acc: 0.933\n",
      "epoch: 23, loss: 0.248, acc: 0.000, val_loss: 0.224, val_acc: 0.934\n",
      "epoch: 24, loss: 0.242, acc: 0.000, val_loss: 0.22, val_acc: 0.935\n",
      "epoch: 25, loss: 0.237, acc: 0.000, val_loss: 0.217, val_acc: 0.936\n",
      "epoch: 26, loss: 0.231, acc: 0.000, val_loss: 0.213, val_acc: 0.937\n",
      "epoch: 27, loss: 0.226, acc: 0.000, val_loss: 0.21, val_acc: 0.938\n",
      "epoch: 28, loss: 0.222, acc: 0.000, val_loss: 0.207, val_acc: 0.939\n",
      "epoch: 29, loss: 0.217, acc: 0.000, val_loss: 0.204, val_acc: 0.940\n",
      "epoch: 30, loss: 0.213, acc: 0.000, val_loss: 0.201, val_acc: 0.941\n",
      "epoch: 31, loss: 0.209, acc: 0.000, val_loss: 0.198, val_acc: 0.941\n",
      "epoch: 32, loss: 0.205, acc: 0.000, val_loss: 0.195, val_acc: 0.942\n",
      "epoch: 33, loss: 0.201, acc: 0.000, val_loss: 0.193, val_acc: 0.943\n",
      "epoch: 34, loss: 0.198, acc: 0.000, val_loss: 0.19, val_acc: 0.944\n",
      "epoch: 35, loss: 0.194, acc: 0.000, val_loss: 0.188, val_acc: 0.944\n",
      "epoch: 36, loss: 0.191, acc: 0.000, val_loss: 0.186, val_acc: 0.945\n",
      "epoch: 37, loss: 0.187, acc: 0.000, val_loss: 0.183, val_acc: 0.946\n",
      "epoch: 38, loss: 0.184, acc: 0.000, val_loss: 0.181, val_acc: 0.946\n",
      "epoch: 39, loss: 0.181, acc: 0.000, val_loss: 0.179, val_acc: 0.947\n",
      "epoch: 40, loss: 0.178, acc: 0.000, val_loss: 0.177, val_acc: 0.947\n",
      "epoch: 41, loss: 0.175, acc: 0.000, val_loss: 0.175, val_acc: 0.948\n",
      "epoch: 42, loss: 0.173, acc: 0.000, val_loss: 0.173, val_acc: 0.948\n",
      "epoch: 43, loss: 0.17, acc: 0.000, val_loss: 0.172, val_acc: 0.949\n",
      "epoch: 44, loss: 0.167, acc: 0.000, val_loss: 0.17, val_acc: 0.949\n",
      "epoch: 45, loss: 0.165, acc: 0.000, val_loss: 0.168, val_acc: 0.950\n",
      "epoch: 46, loss: 0.162, acc: 0.000, val_loss: 0.167, val_acc: 0.950\n",
      "epoch: 47, loss: 0.16, acc: 0.000, val_loss: 0.165, val_acc: 0.951\n",
      "epoch: 48, loss: 0.158, acc: 0.000, val_loss: 0.164, val_acc: 0.951\n",
      "epoch: 49, loss: 0.155, acc: 0.000, val_loss: 0.162, val_acc: 0.952\n",
      "epoch: 50, loss: 0.153, acc: 0.000, val_loss: 0.161, val_acc: 0.952\n",
      "epoch: 51, loss: 0.151, acc: 0.000, val_loss: 0.16, val_acc: 0.952\n",
      "epoch: 52, loss: 0.149, acc: 0.000, val_loss: 0.158, val_acc: 0.953\n",
      "epoch: 53, loss: 0.147, acc: 0.000, val_loss: 0.157, val_acc: 0.953\n",
      "epoch: 54, loss: 0.145, acc: 0.000, val_loss: 0.156, val_acc: 0.953\n",
      "epoch: 55, loss: 0.143, acc: 0.000, val_loss: 0.155, val_acc: 0.954\n",
      "epoch: 56, loss: 0.141, acc: 0.000, val_loss: 0.153, val_acc: 0.954\n",
      "epoch: 57, loss: 0.139, acc: 0.000, val_loss: 0.152, val_acc: 0.954\n",
      "epoch: 58, loss: 0.138, acc: 0.000, val_loss: 0.151, val_acc: 0.955\n",
      "epoch: 59, loss: 0.136, acc: 0.000, val_loss: 0.15, val_acc: 0.955\n",
      "epoch: 60, loss: 0.134, acc: 0.000, val_loss: 0.149, val_acc: 0.955\n",
      "epoch: 61, loss: 0.133, acc: 0.000, val_loss: 0.148, val_acc: 0.955\n",
      "epoch: 62, loss: 0.131, acc: 0.000, val_loss: 0.147, val_acc: 0.956\n",
      "epoch: 63, loss: 0.129, acc: 0.000, val_loss: 0.146, val_acc: 0.956\n",
      "epoch: 64, loss: 0.128, acc: 0.000, val_loss: 0.145, val_acc: 0.956\n",
      "epoch: 65, loss: 0.126, acc: 0.000, val_loss: 0.144, val_acc: 0.957\n",
      "epoch: 66, loss: 0.125, acc: 0.000, val_loss: 0.143, val_acc: 0.957\n",
      "epoch: 67, loss: 0.123, acc: 0.000, val_loss: 0.143, val_acc: 0.957\n",
      "epoch: 68, loss: 0.122, acc: 0.000, val_loss: 0.142, val_acc: 0.957\n",
      "epoch: 69, loss: 0.121, acc: 0.000, val_loss: 0.141, val_acc: 0.957\n",
      "epoch: 70, loss: 0.119, acc: 0.000, val_loss: 0.14, val_acc: 0.958\n",
      "epoch: 71, loss: 0.118, acc: 0.000, val_loss: 0.139, val_acc: 0.958\n",
      "epoch: 72, loss: 0.116, acc: 0.000, val_loss: 0.139, val_acc: 0.958\n",
      "epoch: 73, loss: 0.115, acc: 0.000, val_loss: 0.138, val_acc: 0.958\n",
      "epoch: 74, loss: 0.114, acc: 0.000, val_loss: 0.137, val_acc: 0.958\n",
      "epoch: 75, loss: 0.113, acc: 0.000, val_loss: 0.137, val_acc: 0.959\n",
      "epoch: 76, loss: 0.111, acc: 0.000, val_loss: 0.136, val_acc: 0.959\n",
      "epoch: 77, loss: 0.11, acc: 0.000, val_loss: 0.135, val_acc: 0.959\n",
      "epoch: 78, loss: 0.109, acc: 0.000, val_loss: 0.135, val_acc: 0.959\n",
      "epoch: 79, loss: 0.108, acc: 0.000, val_loss: 0.134, val_acc: 0.959\n",
      "epoch: 80, loss: 0.107, acc: 0.000, val_loss: 0.134, val_acc: 0.960\n",
      "epoch: 81, loss: 0.106, acc: 0.000, val_loss: 0.133, val_acc: 0.960\n",
      "epoch: 82, loss: 0.105, acc: 0.000, val_loss: 0.132, val_acc: 0.960\n",
      "epoch: 83, loss: 0.104, acc: 0.000, val_loss: 0.132, val_acc: 0.960\n",
      "epoch: 84, loss: 0.103, acc: 0.000, val_loss: 0.131, val_acc: 0.960\n",
      "epoch: 85, loss: 0.102, acc: 0.000, val_loss: 0.131, val_acc: 0.960\n",
      "epoch: 86, loss: 0.101, acc: 0.000, val_loss: 0.13, val_acc: 0.961\n",
      "epoch: 87, loss: 0.0996, acc: 0.000, val_loss: 0.13, val_acc: 0.961\n",
      "epoch: 88, loss: 0.0986, acc: 0.000, val_loss: 0.129, val_acc: 0.961\n",
      "epoch: 89, loss: 0.0976, acc: 0.000, val_loss: 0.129, val_acc: 0.961\n",
      "epoch: 90, loss: 0.0967, acc: 0.000, val_loss: 0.128, val_acc: 0.961\n",
      "epoch: 91, loss: 0.0958, acc: 0.000, val_loss: 0.128, val_acc: 0.961\n",
      "epoch: 92, loss: 0.0949, acc: 0.000, val_loss: 0.128, val_acc: 0.961\n",
      "epoch: 93, loss: 0.094, acc: 0.000, val_loss: 0.127, val_acc: 0.962\n",
      "epoch: 94, loss: 0.0931, acc: 0.000, val_loss: 0.127, val_acc: 0.962\n",
      "epoch: 95, loss: 0.0923, acc: 0.000, val_loss: 0.126, val_acc: 0.962\n",
      "epoch: 96, loss: 0.0914, acc: 0.000, val_loss: 0.126, val_acc: 0.962\n",
      "epoch: 97, loss: 0.0906, acc: 0.000, val_loss: 0.126, val_acc: 0.962\n",
      "epoch: 98, loss: 0.0898, acc: 0.000, val_loss: 0.125, val_acc: 0.962\n",
      "epoch: 99, loss: 0.089, acc: 0.000, val_loss: 0.125, val_acc: 0.962\n",
      "epoch: 100, loss: 0.0882, acc: 0.000, val_loss: 0.124, val_acc: 0.962\n"
     ]
    }
   ],
   "source": [
    "x_,t_=shuffle(x_train,t_train)\n",
    "\n",
    "epochs=100\n",
    "batch_size=100\n",
    "n_batches_train=x_train.shape[0]//batch_size\n",
    "n_batches_val=x_val.shape[0]//batch_size\n",
    "hist={'val_loss':[],'val_accuracy':[]}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for batch in range(n_batches_train):\n",
    "        start=batch*batch_size\n",
    "        end=start+batch_size\n",
    "        train_step(x_[start:end],t_[start:end])\n",
    "    \n",
    "    for batch in range(n_batches_val):\n",
    "        start=batch*batch_size\n",
    "        end=start+batch_size\n",
    "        val_step(x_val[start:end],t_val[start:end])\n",
    "        \n",
    "    hist['val_loss'].append(val_loss.result())\n",
    "    hist['val_accuracy'].append(val_acc.result())\n",
    "  \n",
    "    print('epoch: {}, loss: {:.3}, acc: {:.3f}, val_loss: {:.3}, val_acc: {:.3f}'.format(epoch+1,train_loss.result(),train_acc.result(),val_loss.result(),val_acc.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss=hist['val_loss']\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.rc('font',family='serif')\n",
    "plt.plot(range(len(val_loss)),val_loss,color='black',linewidth=1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.08838139>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss=metrics.Mean()\n",
    "test_acc=metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def test_step(x,t):\n",
    "    preds=model(x)\n",
    "    loss=compute_loss(t,preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(t,preds)\n",
    "    return loss\n",
    "\n",
    "test_step(x_test,t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.0884, test_acc: 0.974\n"
     ]
    }
   ],
   "source": [
    "print('test_loss: {:.3}, test_acc: {:.3f}'.format(test_loss.result(),test_acc.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
