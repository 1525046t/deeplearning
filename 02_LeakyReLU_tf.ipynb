{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,LeakyReLU\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(Model):\n",
    "    def __init__(self,hidden_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.l1=Dense(hidden_dim)\n",
    "        self.a1=LeakyReLU(0.01)\n",
    "        self.l2=Dense(hidden_dim)\n",
    "        self.a2=LeakyReLU(0.01)\n",
    "        self.l3=Dense(hidden_dim)\n",
    "        self.a3=LeakyReLU(0.01)\n",
    "        self.l4=Dense(output_dim,activation='softmax')\n",
    "        self.ls=[self.l1,self.a1,self.l2,self.a2,self.l3,self.a3,self.l4]\n",
    "        \n",
    "    def call(self,x):\n",
    "        for layer in self.ls:\n",
    "            x=layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=datasets.mnist\n",
    "(x_train,t_train),(x_test,t_test)=mnist.load_data()\n",
    "\n",
    "x_train=(x_train.reshape(-1,784)/255).astype(np.float32)\n",
    "x_test=(x_test.reshape(-1,784)/255).astype(np.float32)\n",
    "t_train=np.eye(10)[t_train].astype(np.float32)\n",
    "t_test=np.eye(10)[t_test].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DNN(200,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.119, acc: 0.813\n",
      "epoch: 1, loss: 2.169, acc: 0.869\n",
      "epoch: 2, loss: 1.834, acc: 0.889\n",
      "epoch: 3, loss: 1.668, acc: 0.898\n",
      "epoch: 4, loss: 1.587, acc: 0.903\n",
      "epoch: 5, loss: 1.554, acc: 0.905\n",
      "epoch: 6, loss: 1.552, acc: 0.905\n",
      "epoch: 7, loss: 1.724, acc: 0.894\n",
      "epoch: 8, loss: 2.019, acc: 0.876\n",
      "epoch: 9, loss: 2.405, acc: 0.852\n",
      "epoch: 10, loss: 3.135, acc: 0.806\n",
      "epoch: 11, loss: 3.817, acc: 0.764\n",
      "epoch: 12, loss: 4.400, acc: 0.728\n",
      "epoch: 13, loss: 4.914, acc: 0.696\n",
      "epoch: 14, loss: 5.416, acc: 0.664\n",
      "epoch: 15, loss: 5.853, acc: 0.637\n",
      "epoch: 16, loss: 6.333, acc: 0.608\n",
      "epoch: 17, loss: 6.788, acc: 0.579\n",
      "epoch: 18, loss: 7.195, acc: 0.554\n",
      "epoch: 19, loss: 7.562, acc: 0.531\n",
      "epoch: 20, loss: 7.894, acc: 0.511\n",
      "epoch: 21, loss: 8.195, acc: 0.492\n",
      "epoch: 22, loss: 8.471, acc: 0.475\n",
      "epoch: 23, loss: 8.723, acc: 0.459\n",
      "epoch: 24, loss: 8.955, acc: 0.445\n",
      "epoch: 25, loss: 9.170, acc: 0.431\n",
      "epoch: 26, loss: 9.368, acc: 0.419\n",
      "epoch: 27, loss: 9.552, acc: 0.408\n",
      "epoch: 28, loss: 9.724, acc: 0.397\n",
      "epoch: 29, loss: 9.884, acc: 0.387\n"
     ]
    }
   ],
   "source": [
    "criterion=losses.CategoricalCrossentropy()\n",
    "optimizer=optimizers.SGD(learning_rate=0.1)\n",
    "train_loss=metrics.Mean()\n",
    "train_acc=metrics.CategoricalAccuracy()\n",
    "\n",
    "def compute_loss(t,y):\n",
    "    return criterion(t,y)\n",
    "\n",
    "def train_step(x,t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds=model(x)\n",
    "        loss=compute_loss(preds,t)\n",
    "    grads=tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_acc(t,preds)\n",
    "    return loss\n",
    "\n",
    "epochs=30\n",
    "batch_size=100\n",
    "n_batches=x_train.shape[0]//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    x_,t_=shuffle(x_train,t_train)\n",
    "    \n",
    "    for batch in range(n_batches):\n",
    "        start=batch*batch_size\n",
    "        end=start+batch_size\n",
    "        train_step(x_[start:end],t_[start:end])\n",
    "    \n",
    "    print('epoch: {}, loss: {:.3f}, acc: {:.3f}'.format(epoch,train_loss.result(),train_acc.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 14.574, test_acc:0.096\n"
     ]
    }
   ],
   "source": [
    "test_loss=metrics.Mean()\n",
    "test_acc=metrics.CategoricalAccuracy()\n",
    "\n",
    "def test_step(x,t):\n",
    "    preds=model(x)\n",
    "    loss=compute_loss(t,preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(t,preds)\n",
    "    return loss\n",
    "\n",
    "test_step(x_test,t_test)\n",
    "\n",
    "print('test_loss: {:.3f}, test_acc:{:.3f}'.format(test_loss.result(),test_acc.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
